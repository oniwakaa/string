# Generated by SmolLM3-3B on 2024-12-19
"""
Polyglot Code Quality Agent - Advanced Multi-Phase Analysis

This module implements a sophisticated code quality analysis system with three phases:
- Phase 0: Language Detection using Pygments
- Phase 1: Dynamic Linter Selection (static analysis)
- Phase 2: Qualitative LLM Review using Qwen3-1.7B

The agent can analyze code in multiple programming languages with language-specific
tools and provides both objective and subjective quality assessments.
"""

import asyncio
import json
import os
import tempfile
from typing import Dict, List, Any, Optional

import pygments
from pygments.lexers import guess_lexer
from pygments.util import ClassNotFound

from .base import BaseAgent, Task, Result


class CodeQualityAgent(BaseAgent):
    """
    Advanced polyglot code quality analyzer with hybrid static + qualitative analysis.
    
    This agent implements a three-phase architecture:
    1. Language detection using Pygments
    2. Dynamic linter selection and execution
    3. Qualitative LLM review using Qwen3-1.7B
    """
    
    def __init__(self):
        super().__init__(
            name="Qwen3_CodeQualityAgent",
            role="code_quality_analyzer",
            model_identifier="./models/qwen/qwen3-1.7b-q4_k_m.gguf"
        )
        
        # Linter registry - maps language names to linter configurations
        self.linter_registry = {
            'Python': {
                'command': ['pylint', '--output-format=json', '--disable=all', '--enable=E,W,C,R'],
                'output_type': 'json',
                'file_extension': '.py',
                'fallback_commands': [
                    ['pyflakes'],
                    ['python', '-m', 'py_compile']
                ]
            },
            'JavaScript': {
                'command': ['eslint', '--format=json'],
                'output_type': 'json', 
                'file_extension': '.js',
                'fallback_commands': [
                    ['jshint', '--reporter=unix']
                ]
            },
            'TypeScript': {
                'command': ['tslint', '--format=json'],
                'output_type': 'json',
                'file_extension': '.ts',
                'fallback_commands': [
                    ['tsc', '--noEmit']
                ]
            },
            'Java': {
                'command': ['checkstyle', '-f', 'xml'],
                'output_type': 'xml',
                'file_extension': '.java',
                'fallback_commands': [
                    ['javac', '-Xlint:all']
                ]
            },
            'C++': {
                'command': ['cppcheck', '--xml'],
                'output_type': 'xml', 
                'file_extension': '.cpp',
                'fallback_commands': [
                    ['clang-tidy', '--format-style=json']
                ]
            },
            'C': {
                'command': ['cppcheck', '--xml'],
                'output_type': 'xml',
                'file_extension': '.c',
                'fallback_commands': [
                    ['gcc', '-Wall', '-Wextra', '-c']
                ]
            },
            'Go': {
                'command': ['golint'],
                'output_type': 'text',
                'file_extension': '.go',
                'fallback_commands': [
                    ['go', 'vet'],
                    ['gofmt', '-d']
                ]
            },
            'Rust': {
                'command': ['cargo', 'clippy', '--message-format=json'],
                'output_type': 'json',
                'file_extension': '.rs',
                'fallback_commands': [
                    ['rustc', '--error-format=json']
                ]
            },
            'PHP': {
                'command': ['phpcs', '--report=json'],
                'output_type': 'json',
                'file_extension': '.php',
                'fallback_commands': [
                    ['php', '-l']
                ]
            },
            'Ruby': {
                'command': ['rubocop', '--format=json'],
                'output_type': 'json',
                'file_extension': '.rb',
                'fallback_commands': [
                    ['ruby', '-c']
                ]
            }
        }
        
        # Qwen3 specific configuration for code analysis
        self.qwen_config = {
            'n_ctx': 4096,  # Context window
            'n_batch': 512,
            'n_gpu_layers': -1,  # Use M4 GPU
            'use_mmap': True,
            'use_mlock': False,
            'low_vram': True,
            'verbose': False
        }
        
        # Generation parameters for code analysis
        self.generation_config = {
            'max_tokens': 1024,
            'temperature': 0.4,  # Balanced for analysis
            'top_p': 0.85,
            'top_k': 25,
            'repeat_penalty': 1.1,
            'stop': ["<|endoftext|>", "<|im_end|>", "```"],
        }
    
    def lazy_load_model(self):
        """
        Load the Qwen3-1.7B GGUF model for qualitative analysis.
        
        This model is specifically optimized for code analysis tasks
        and runs efficiently on MacBook Air M4.
        """
        if self.model is None:
            try:
                from llama_cpp import Llama
                
                self.status = 'loading_model'
                print(f"🔄 Loading Qwen3-1.7B model for {self.name}...")
                
                # Verify model file exists
                if not os.path.exists(self.model_identifier):
                    raise FileNotFoundError(f"Model file not found: {self.model_identifier}")
                
                # Load model with optimizations
                self.model = Llama(
                    model_path=self.model_identifier,
                    **self.qwen_config
                )
                
                self.status = 'ready'
                print(f"✅ Qwen3-1.7B model loaded successfully for {self.name}")
                
            except Exception as e:
                self.status = 'error'
                error_msg = f"❌ Failed to load Qwen3-1.7B model for {self.name}: {str(e)}"
                print(error_msg)
                raise RuntimeError(error_msg)
    
    async def execute(self, task: Task) -> Result:
        """
        Execute the three-phase code quality analysis.
        
        Phase 0: Language Detection
        Phase 1: Dynamic Linter Selection  
        Phase 2: Qualitative LLM Review
        """
        try:
            # Extract code from task context
            code = self._extract_code_from_task(task)
            if not code:
                return Result(
                    task_id=task.task_id,
                    status="failure",
                    output="",
                    error_message="No code found in task context for analysis"
                )
            
            # Phase 0: Language Detection
            language = await self._detect_language(code)
            print(f"🔍 Detected language: {language}")
            
            # Phase 1: Dynamic Linter Selection and Execution
            static_report = await self._run_static_analysis(code, language)
            
            # Phase 2: Qualitative LLM Review
            qualitative_review = await self._run_qualitative_analysis(code, language, static_report)
            
            # Assemble final result
            final_output = {
                'language': language,
                'static_report': static_report,
                'qualitative_review': qualitative_review,
                'analysis_summary': self._create_analysis_summary(static_report, qualitative_review)
            }
            
            return Result(
                task_id=task.task_id,
                status="success",
                output=final_output
            )
            
        except Exception as e:
            return Result(
                task_id=task.task_id,
                status="failure",
                output="",
                error_message=f"Code quality analysis failed: {str(e)}"
            )
    
    def _extract_code_from_task(self, task: Task) -> Optional[str]:
        """
        Extract code from task context or prompt.
        """
        # Try to get code from context first
        if task.context:
            # Look for code in various context keys
            for key in ['code', 'source_code', 'content', 'text']:
                if key in task.context and task.context[key]:
                    return str(task.context[key])
            
            # Check for dependency outputs (from CodebaseExpertAgent)
            for key, value in task.context.items():
                if key.startswith('dependency_') and isinstance(value, dict):
                    if 'answer' in value:
                        return str(value['answer'])
        
        # Fallback to extracting from prompt
        prompt = task.prompt.strip()
        
        # Look for code blocks in markdown format
        if '```' in prompt:
            lines = prompt.split('\n')
            in_code_block = False
            code_lines = []
            
            for line in lines:
                if line.strip().startswith('```'):
                    if in_code_block:
                        break  # End of code block
                    else:
                        in_code_block = True  # Start of code block
                        continue
                elif in_code_block:
                    code_lines.append(line)
            
            if code_lines:
                return '\n'.join(code_lines)
        
        # If no code blocks found, assume entire prompt is code
        return prompt
    
    async def _detect_language(self, code: str) -> str:
        """
        Phase 0: Detect programming language using Pygments.
        """
        try:
            lexer = guess_lexer(code)
            language_name = lexer.name
            
            # Normalize language names to match our linter registry
            language_mapping = {
                'Python': 'Python',
                'JavaScript': 'JavaScript',
                'TypeScript': 'TypeScript', 
                'Java': 'Java',
                'C++': 'C++',
                'C': 'C',
                'Go': 'Go',
                'Rust': 'Rust',
                'PHP': 'PHP',
                'Ruby': 'Ruby',
                'Python 3': 'Python',
                'ECMAScript': 'JavaScript',
                'JS': 'JavaScript'
            }
            
            return language_mapping.get(language_name, language_name)
            
        except ClassNotFound:
            print("⚠️ Could not detect language, proceeding with generic analysis")
            return "Unknown"
        except Exception as e:
            print(f"⚠️ Language detection error: {e}")
            return "Unknown"
    
    async def _run_static_analysis(self, code: str, language: str) -> Optional[Dict[str, Any]]:
        """
        Phase 1: Run static analysis using language-specific linters.
        """
        if language not in self.linter_registry:
            print(f"⚠️ No linter available for {language}, skipping static analysis")
            return None
        
        linter_config = self.linter_registry[language]
        
        # Create temporary file with appropriate extension
        try:
            with tempfile.NamedTemporaryFile(
                mode='w',
                suffix=linter_config['file_extension'],
                delete=False
            ) as temp_file:
                temp_file.write(code)
                temp_file_path = temp_file.name
            
            # Try primary linter command
            try:
                result = await self._execute_linter(
                    linter_config['command'], 
                    temp_file_path,
                    linter_config['output_type']
                )
                if result:
                    return result
            except Exception as e:
                print(f"⚠️ Primary linter failed: {e}")
            
            # Try fallback commands
            for fallback_cmd in linter_config.get('fallback_commands', []):
                try:
                    result = await self._execute_linter(
                        fallback_cmd + [temp_file_path],
                        temp_file_path,
                        'text'  # Fallbacks usually produce text output
                    )
                    if result:
                        return result
                except Exception as e:
                    print(f"⚠️ Fallback linter failed: {e}")
                    continue
            
            print(f"⚠️ All linters failed for {language}")
            return None
            
        finally:
            # Clean up temporary file
            try:
                os.unlink(temp_file_path)
            except:
                pass
    
    async def _execute_linter(self, command: List[str], file_path: str, output_type: str) -> Optional[Dict[str, Any]]:
        """
        Execute a linter command asynchronously.
        """
        try:
            # Add file path to command if not already included
            if file_path not in command:
                command.append(file_path)
            
            # Execute linter asynchronously
            process = await asyncio.create_subprocess_exec(
                *command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            # Parse output based on type
            if output_type == 'json' and stdout:
                try:
                    parsed_output = json.loads(stdout.decode())
                    return {
                        'linter': command[0],
                        'output_type': output_type,
                        'issues': parsed_output,
                        'raw_output': stdout.decode(),
                        'stderr': stderr.decode() if stderr else None
                    }
                except json.JSONDecodeError:
                    # Fallback to text if JSON parsing fails
                    pass
            
            # Handle text output
            output_text = stdout.decode() if stdout else stderr.decode()
            if output_text.strip():
                return {
                    'linter': command[0],
                    'output_type': 'text',
                    'issues': output_text.strip(),
                    'raw_output': output_text,
                    'stderr': stderr.decode() if stderr else None
                }
            
            return None
            
        except FileNotFoundError:
            print(f"⚠️ Linter {command[0]} not found")
            return None
        except Exception as e:
            print(f"⚠️ Linter execution error: {e}")
            return None
    
    async def _run_qualitative_analysis(self, code: str, language: str, static_report: Optional[Dict[str, Any]]) -> str:
        """
        Phase 2: Run qualitative analysis using Qwen3-1.7B LLM.
        """
        try:
            # Lazy load model if needed
            if self.model is None:
                self.lazy_load_model()
            
            # Create dynamic prompt based on context
            prompt = self._create_qualitative_prompt(code, language, static_report)
            
            # Generate qualitative analysis
            response = self.model(
                prompt,
                **self.generation_config,
                echo=False
            )
            
            generated_text = response['choices'][0]['text'].strip()
            
            # Clean up response
            if generated_text.endswith('<|im_end|>'):
                generated_text = generated_text[:-10].strip()
            
            return generated_text
            
        except Exception as e:
            return f"Qualitative analysis failed: {str(e)}"
    
    def _create_qualitative_prompt(self, code: str, language: str, static_report: Optional[Dict[str, Any]]) -> str:
        """
        Create a dynamic prompt for qualitative analysis based on available context.
        """
        base_prompt = f"""You are an expert code reviewer analyzing {language} code. Provide a comprehensive qualitative analysis focusing on:

1. Code Logic and Algorithm Efficiency
2. Readability and Maintainability  
3. Best Practices and Design Patterns
4. Potential Security Issues
5. Performance Considerations

Code to analyze:
```{language.lower()}
{code}
```

"""
        
        if static_report:
            # Case with static linter report
            base_prompt += f"""
Static Linter Report (from {static_report.get('linter', 'unknown')}):
{json.dumps(static_report.get('issues', {}), indent=2) if isinstance(static_report.get('issues'), dict) else static_report.get('issues', '')}

Please focus on qualitative aspects NOT covered by the static analysis above. Ignore issues already detected by the linter and concentrate on:
- Code architecture and design quality
- Logic flow and algorithmic efficiency  
- Readability and maintainability factors
- Potential performance bottlenecks
- Security considerations

"""
        else:
            # Case without static linter report
            base_prompt += """
Since no static analysis tools were available for this language, please provide a complete qualitative analysis including:
- Syntax and style issues (if any)
- Code architecture and design quality
- Logic flow and algorithmic efficiency
- Readability and maintainability factors  
- Potential bugs or errors
- Security considerations
- Performance optimization opportunities

"""
        
        base_prompt += """
Analysis (be specific and actionable):
"""
        
        return base_prompt
    
    def _create_analysis_summary(self, static_report: Optional[Dict[str, Any]], qualitative_review: str) -> str:
        """
        Create a comprehensive summary of both static and qualitative analysis.
        """
        summary_parts = []
        
        if static_report:
            linter_name = static_report.get('linter', 'Static Analysis')
            summary_parts.append(f"✅ Static Analysis ({linter_name}): Issues detected and reported")
        else:
            summary_parts.append("⚠️ Static Analysis: No language-specific linter available")
        
        summary_parts.append(f"✅ Qualitative Review: Comprehensive analysis completed")
        
        # Extract key points from qualitative review
        if len(qualitative_review) > 100:
            summary_parts.append("📋 Key areas covered: Logic, Readability, Performance, Security, Best Practices")
        
        return " | ".join(summary_parts)
    
    def get_model_info(self) -> dict:
        """
        Get information about the loaded model and supported languages.
        """
        return {
            'model_name': 'Qwen3-1.7B',
            'quantization': 'Q4_K_M', 
            'format': 'GGUF',
            'context_length': self.qwen_config['n_ctx'],
            'loaded': self.model is not None,
            'status': self.status,
            'supported_languages': list(self.linter_registry.keys()),
            'analysis_phases': ['Language Detection', 'Static Analysis', 'Qualitative Review'],
            'platform': 'MacBook Air M4'
        } 