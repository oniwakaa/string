[
  {
    "id": "reasoning_001",
    "category": "long_reasoning",
    "prompt": "You are a sophisticated AI assistant helping a data scientist optimize their machine learning pipeline. The dataset contains 1.2 million samples with 247 features, including categorical variables, numerical data, and text embeddings. The current model achieves 84.3% accuracy but takes 45 minutes to train. The scientist wants to reduce training time to under 20 minutes while maintaining at least 82% accuracy. Consider feature selection, model architecture changes, data preprocessing optimizations, and hardware utilization strategies. Provide a detailed step-by-step optimization plan with expected time savings and accuracy trade-offs for each recommendation.",
    "expected_themes": ["optimization", "machine_learning", "efficiency", "trade-offs"],
    "token_estimate": 1800
  },
  {
    "id": "reasoning_002", 
    "category": "long_reasoning",
    "prompt": "Analyze the economic implications of implementing a universal basic income (UBI) system in a developed country with 50 million citizens. Consider the following factors: current welfare spending ($180 billion annually), average household income ($65,000), unemployment rate (6.2%), and projected automation impact (30% of jobs at risk over 10 years). Evaluate three UBI scenarios: $500/month, $1000/month, and $1500/month per citizen. For each scenario, calculate the total annual cost, funding mechanisms, potential economic multiplier effects, impact on work incentives, and long-term sustainability. Address concerns about inflation, labor market disruption, and social cohesion.",
    "expected_themes": ["economics", "policy", "social_impact", "sustainability"],
    "token_estimate": 2100
  },
  {
    "id": "memory_001",
    "category": "memory_recall",
    "prompt": "In our previous conversation, you mentioned that the MemOS system uses a multi-layered architecture with textual, parametric, and activation memories. Can you recall the specific details about how the tree-based textual memory handles conflict resolution when storing contradictory information? Also, what was the performance benchmark we discussed for the quantized model's inference latency?",
    "expected_themes": ["system_architecture", "memory_management", "performance"],
    "token_estimate": 600
  },
  {
    "id": "memory_002",
    "category": "memory_recall", 
    "prompt": "Earlier, we discussed the optimization of the quantization pipeline for SmolLM3-3B. What were the three main bottlenecks identified in the original 9-line implementation, and how did we address each one? Please also recall the specific memory reduction percentage we achieved with the 4-bit quantization.",
    "expected_themes": ["optimization", "quantization", "performance_metrics"],
    "token_estimate": 450
  },
  {
    "id": "code_001",
    "category": "code_generation",
    "prompt": "Create a robust Python class for managing distributed training of large language models across multiple GPUs. The class should handle: 1) Dynamic load balancing based on GPU memory availability, 2) Fault tolerance with automatic recovery from GPU failures, 3) Gradient synchronization with compression to reduce communication overhead, 4) Memory-efficient checkpointing that doesn't block training, 5) Real-time monitoring of training metrics and resource utilization. Include comprehensive error handling, logging, and support for both data parallel and model parallel training strategies. The implementation should be compatible with PyTorch and support mixed precision training.",
    "expected_themes": ["distributed_computing", "machine_learning", "system_design"],
    "token_estimate": 1200
  },
  {
    "id": "code_002",
    "category": "code_refactor",
    "prompt": "Refactor this legacy authentication system to improve security, performance, and maintainability. The current system uses plain text passwords, has no rate limiting, lacks proper session management, and has SQL injection vulnerabilities. Transform it into a modern, secure system with: bcrypt password hashing, JWT-based authentication, Redis session store, rate limiting with exponential backoff, SQL parameterized queries, comprehensive input validation, audit logging, and multi-factor authentication support. Maintain backward compatibility where possible and provide a migration strategy for existing users.",
    "expected_themes": ["security", "refactoring", "authentication", "modernization"],
    "token_estimate": 1000
  },
  {
    "id": "edge_001",
    "category": "edge_case",
    "prompt": "Hi",
    "expected_themes": ["greeting"],
    "token_estimate": 20
  },
  {
    "id": "edge_002", 
    "category": "edge_case",
    "prompt": "üöÄüíªü§ñ Hey there! I'm working on this super cool AI project and I need your help!!! Can you explain quantum computing in a way that my 5-year-old nephew would understand? But also make it sound like a pirate adventure??? üè¥‚Äç‚ò†Ô∏è‚öìÔ∏è And maybe add some emojis throughout? Thanks a million! üôè‚ú®",
    "expected_themes": ["explanation", "creative_writing", "quantum_computing"],
    "token_estimate": 300
  },
  {
    "id": "edge_003",
    "category": "edge_case", 
    "prompt": "Generate a comprehensive analysis of the socioeconomic implications of artificial intelligence adoption in emerging markets, with particular focus on the intersection of technological leapfrogging, informal economy digitization, and the potential for AI-driven financial inclusion. Consider the complex interplay between traditional banking systems, mobile money platforms, and AI-powered credit scoring algorithms in countries with limited digital infrastructure. Evaluate case studies from Kenya's M-Pesa system, India's Unified Payments Interface, and Bangladesh's digital microfinance initiatives. Address regulatory challenges, data privacy concerns in low-governance environments, and the risk of algorithmic bias perpetuating existing inequalities. Provide specific recommendations for policy frameworks that balance innovation with consumer protection, considering the unique challenges of cross-border digital payments, cryptocurrency adoption, and the need for interoperability between traditional and digital financial systems. Include projections for market penetration rates, economic impact metrics, and timeline estimates for achieving widespread AI-driven financial inclusion across different emerging market segments.",
    "expected_themes": ["economic_analysis", "technology_adoption", "financial_inclusion"],
    "token_estimate": 2500
  },
  {
    "id": "reasoning_003",
    "category": "long_reasoning",
    "prompt": "Design a comprehensive disaster recovery and business continuity plan for a multinational technology company with operations in 15 countries, 50,000 employees, and critical dependencies on cloud infrastructure, global supply chains, and real-time data processing. The plan must address various scenarios including cyberattacks, natural disasters, pandemic-related disruptions, geopolitical tensions, and cascading infrastructure failures. Consider the company's diverse operations: software development (40% of workforce), manufacturing (25%), sales and marketing (20%), and support services (15%). Evaluate backup strategies for critical systems, alternative supply chain routes, remote work capabilities, data redundancy across multiple regions, and coordination protocols for crisis management. Include detailed timelines for recovery phases, resource allocation strategies, communication plans for stakeholders, and methods for testing and updating the plan. Address legal and regulatory compliance requirements across different jurisdictions, insurance considerations, and financial impact projections for various disruption scenarios.",
    "expected_themes": ["risk_management", "business_continuity", "strategic_planning"],
    "token_estimate": 2000
  },
  {
    "id": "code_003",
    "category": "code_generation",
    "prompt": "Implement a high-performance, thread-safe caching system in Python that supports multiple eviction policies (LRU, LFU, FIFO, Random), automatic cache warming, distributed cache invalidation, and smart prefetching based on access patterns. The system should handle concurrent reads and writes efficiently, provide detailed metrics and monitoring, support serialization of complex objects, and include a plugin architecture for custom cache backends (Redis, Memcached, in-memory). Add features for cache partitioning, compression, encryption, and graceful degradation during backend failures.",
    "expected_themes": ["caching", "concurrency", "system_design", "performance"],
    "token_estimate": 1500
  },
  {
    "id": "memory_003",
    "category": "memory_recall",
    "prompt": "Based on our earlier discussion about the MemOS architecture, can you recall the specific configuration parameters we used for the FAISS vector database integration? What were the index type, dimension settings, and similarity metrics we decided on for optimal performance with the SmolLM3 embeddings?",
    "expected_themes": ["vector_database", "configuration", "embeddings"],
    "token_estimate": 400
  },
  {
    "id": "reasoning_004",
    "category": "long_reasoning", 
    "prompt": "A research team is developing a novel approach to carbon capture using engineered microorganisms that can convert atmospheric CO2 into useful compounds. The current prototype achieves a conversion rate of 2.3 kg CO2 per cubic meter of bioreactor volume per day, with an energy efficiency of 78%. The team needs to scale this technology to industrial levels while addressing several challenges: maintaining organism viability in harsh industrial environments, optimizing nutrient supply chains, managing waste products, ensuring biosafety protocols, and achieving economic viability against traditional carbon capture methods. Evaluate the scaling requirements to process 1000 tons of CO2 daily, calculate infrastructure needs, assess environmental impact, analyze regulatory hurdles, and develop a commercialization strategy. Consider competition from direct air capture technologies, potential partnerships with industrial emitters, and integration with existing carbon credit markets.",
    "expected_themes": ["biotechnology", "environmental_science", "industrial_scaling"],
    "token_estimate": 1900
  },
  {
    "id": "code_004",
    "category": "code_refactor",
    "prompt": "Modernize this monolithic e-commerce application into a microservices architecture. The current system is a single Rails application handling user management, product catalog, inventory, orders, payments, and shipping. It has performance bottlenecks, scalability issues, and deployment challenges. Design a microservices solution with proper service boundaries, API gateways, event-driven communication, distributed transaction management, and service discovery. Include migration strategies, data consistency patterns, monitoring and observability, and disaster recovery plans.",
    "expected_themes": ["microservices", "architecture", "migration", "scalability"],
    "token_estimate": 1300
  },
  {
    "id": "edge_004",
    "category": "edge_case",
    "prompt": "",
    "expected_themes": ["empty_input"],
    "token_estimate": 5
  },
  {
    "id": "memory_004",
    "category": "memory_recall",
    "prompt": "In our optimization discussion, you mentioned specific performance targets for the quantized model. Can you recall what were the maximum acceptable inference latency, memory usage threshold, and accuracy loss percentage we established for the Apple Silicon deployment?",
    "expected_themes": ["performance_targets", "quantization", "deployment"],
    "token_estimate": 350
  }
] 