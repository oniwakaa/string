# Generated by SmolLM3-3B on 2025-01-01
# Configuration for MemOS with GGUF Model Integration

# MemOS Core Configuration
memos:
  user_id: "default_user"
  session_id: "default_session"
  enable_textual_memory: true
  enable_activation_memory: false
  top_k: 5

# Memory Reader Configuration
mem_reader:
  backend: "simple_struct"
  config:
    llm:
      backend: "gguf"
      config:
        model_name_or_path: "./smollm-quantized/smollm-q4_K_M.gguf"
        max_tokens: 512
        temperature: 0.7
        top_p: 0.9
        top_k: 50
        do_sample: true
        add_generation_prompt: true
    embedder:
      backend: "sentence_transformer"
      config:
        model_name_or_path: "all-MiniLM-L6-v2"
    chunker:
      backend: "sentence"
      config:
        tokenizer_or_token_counter: "gpt2"
        chunk_size: 512
        chunk_overlap: 128
        min_sentences_per_chunk: 1

# Model Configuration (SmolLM3)
model:
  # Path to the model directory (SafeTensors format)
  model_path: "./smollm"
  
  # Generation parameters
  generation:
    max_tokens: 512
    temperature: 0.7
    top_p: 0.9
    top_k: 50
    do_sample: true
    add_generation_prompt: true
    remove_think_prefix: false
    n_ctx: 16384  # Context window size - increased from 4096 to better utilize model's 65536 training context
    n_batch: 512  # Batch size for prompt processing
  
  # Model loading settings
  loading:
    auto_load: true  # Load model automatically on service startup
    validate_on_load: true  # Validate model file before loading

# Service Configuration
service:
  # Health check settings
  health_check:
    enabled: true
    endpoint: "/health"
    include_model_info: true
  
  # API settings
  api:
    host: "0.0.0.0"
    port: 8000
    title: "MemOS with GGUF Integration"
    description: "A persistent service integrating MemOS memory layer with GGUF models"
    version: "1.0.0"

# Memory Integration Configuration
memory:
  # Memory retrieval settings before inference
  retrieval:
    enabled: true
    top_k: 5
    mode: "fast"  # Options: "fast", "fine"
    memory_types: ["All"]  # Options: ["All", "WorkingMemory", "LongTermMemory", "UserMemory"]
  
  # Memory cube configuration
  cube:
    default_cube_id: "default_cube"
    auto_create: true

# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
# Environment Variable Overrides
# The following settings can be overridden by environment variables:
# - GGUF_MODEL_PATH: Path to GGUF model file
# - GGUF_GPU_LAYERS: Number of GPU layers
# - GGUF_THREADS: Number of threads
# - GGUF_MAX_TOKENS: Maximum tokens to generate
# - GGUF_TEMPERATURE: Generation temperature
# - MEMOS_USER_ID: Default user ID
# - MEMOS_TOP_K: Top-k for memory retrieval
# - SERVICE_HOST: Service host
# - SERVICE_PORT: Service port
# - LOG_LEVEL: Logging level 